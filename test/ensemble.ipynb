{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a155d9c7-9f6e-467a-85d9-d1f531b51a96",
   "metadata": {},
   "source": [
    "# Load packages required for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b879511a-ca3d-4518-bff9-e9005fdad298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6f20f-459a-4c3c-bc42-b7463b1cbe06",
   "metadata": {},
   "source": [
    "# Manhattan taxi data (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d85a7c-8b88-42aa-a877-992cfcbeb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "manhattan_final_prep = pd.read_csv(\"gs://final_prep_data/manhattan_final_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cb6422-d147-412e-95c8-3fc9570b2d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>PU_count</th>\n",
       "      <th>lag_pickup_count</th>\n",
       "      <th>PU_month</th>\n",
       "      <th>PU_day_of_month</th>\n",
       "      <th>PU_day_of_week</th>\n",
       "      <th>PU_hour</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>...</th>\n",
       "      <th>landuse_2.0</th>\n",
       "      <th>landuse_3.0</th>\n",
       "      <th>landuse_4.0</th>\n",
       "      <th>landuse_5.0</th>\n",
       "      <th>landuse_6.0</th>\n",
       "      <th>landuse_7.0</th>\n",
       "      <th>landuse_8.0</th>\n",
       "      <th>landuse_9.0</th>\n",
       "      <th>landuse_10.0</th>\n",
       "      <th>landuse_11.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.99</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7.71</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13</td>\n",
       "      <td>7.39</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.20</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID tpep_pickup_datetime  PU_count  lag_pickup_count  PU_month  \\\n",
       "0             4  2022-01-01 00:00:00      11.0               0.0         1   \n",
       "1             4  2022-01-01 01:00:00      10.0              11.0         1   \n",
       "2             4  2022-01-01 02:00:00      20.0              10.0         1   \n",
       "3             4  2022-01-01 03:00:00       7.0              20.0         1   \n",
       "4             4  2022-01-01 04:00:00       6.0               7.0         1   \n",
       "\n",
       "   PU_day_of_month  PU_day_of_week  PU_hour  precip  temp  ...  landuse_2.0  \\\n",
       "0                1               5        0    0.01  7.99  ...       6427.0   \n",
       "1                1               5        1    0.04  7.71  ...       6427.0   \n",
       "2                1               5        2    0.13  7.39  ...       6427.0   \n",
       "3                1               5        3    0.07  7.21  ...       6427.0   \n",
       "4                1               5        4    0.05  7.20  ...       6427.0   \n",
       "\n",
       "   landuse_3.0  landuse_4.0  landuse_5.0  landuse_6.0  landuse_7.0  \\\n",
       "0       1440.0       9061.0        711.0         94.0         81.0   \n",
       "1       1440.0       9061.0        711.0         94.0         81.0   \n",
       "2       1440.0       9061.0        711.0         94.0         81.0   \n",
       "3       1440.0       9061.0        711.0         94.0         81.0   \n",
       "4       1440.0       9061.0        711.0         94.0         81.0   \n",
       "\n",
       "   landuse_8.0  landuse_9.0  landuse_10.0  landuse_11.0  \n",
       "0       1167.0        806.0         120.0         193.0  \n",
       "1       1167.0        806.0         120.0         193.0  \n",
       "2       1167.0        806.0         120.0         193.0  \n",
       "3       1167.0        806.0         120.0         193.0  \n",
       "4       1167.0        806.0         120.0         193.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of the dataframe\n",
    "\n",
    "manhattan_final_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e292584-f9e2-4cda-99cf-2a5dd1855a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286514 entries, 0 to 286513\n",
      "Data columns (total 30 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   PULocationID          286514 non-null  int64  \n",
      " 1   tpep_pickup_datetime  286514 non-null  object \n",
      " 2   PU_count              286514 non-null  float64\n",
      " 3   lag_pickup_count      286514 non-null  float64\n",
      " 4   PU_month              286514 non-null  int64  \n",
      " 5   PU_day_of_month       286514 non-null  int64  \n",
      " 6   PU_day_of_week        286514 non-null  int64  \n",
      " 7   PU_hour               286514 non-null  int64  \n",
      " 8   precip                286514 non-null  float64\n",
      " 9   temp                  286514 non-null  float64\n",
      " 10  frost                 286514 non-null  float64\n",
      " 11  employment_%          286514 non-null  float64\n",
      " 12  income_high_%         286514 non-null  float64\n",
      " 13  income_med_e          286514 non-null  float64\n",
      " 14  poverty_lev_e         286514 non-null  int64  \n",
      " 15  total_pop_e           286514 non-null  int64  \n",
      " 16  female_%              286514 non-null  float64\n",
      " 17  age_65_%              286514 non-null  float64\n",
      " 18  age_med_e             286514 non-null  float64\n",
      " 19  landuse_1.0           286514 non-null  float64\n",
      " 20  landuse_2.0           286514 non-null  float64\n",
      " 21  landuse_3.0           286514 non-null  float64\n",
      " 22  landuse_4.0           286514 non-null  float64\n",
      " 23  landuse_5.0           286514 non-null  float64\n",
      " 24  landuse_6.0           286514 non-null  float64\n",
      " 25  landuse_7.0           286514 non-null  float64\n",
      " 26  landuse_8.0           286514 non-null  float64\n",
      " 27  landuse_9.0           286514 non-null  float64\n",
      " 28  landuse_10.0          286514 non-null  float64\n",
      " 29  landuse_11.0          286514 non-null  float64\n",
      "dtypes: float64(22), int64(7), object(1)\n",
      "memory usage: 65.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info on columns and dtypes\n",
    "\n",
    "manhattan_final_prep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397f3e6-4559-4ad0-821d-6a8d62884d51",
   "metadata": {},
   "source": [
    "# Format Data Part 1: Split the data into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d44bd2a-e3a4-450f-8c9f-f59caaba15c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>lag_pickup_count</th>\n",
       "      <th>PU_month</th>\n",
       "      <th>PU_day_of_month</th>\n",
       "      <th>PU_day_of_week</th>\n",
       "      <th>PU_hour</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>frost</th>\n",
       "      <th>...</th>\n",
       "      <th>landuse_2.0</th>\n",
       "      <th>landuse_3.0</th>\n",
       "      <th>landuse_4.0</th>\n",
       "      <th>landuse_5.0</th>\n",
       "      <th>landuse_6.0</th>\n",
       "      <th>landuse_7.0</th>\n",
       "      <th>landuse_8.0</th>\n",
       "      <th>landuse_9.0</th>\n",
       "      <th>landuse_10.0</th>\n",
       "      <th>landuse_11.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.99</td>\n",
       "      <td>7.94</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.69</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.44</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.31</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.30</td>\n",
       "      <td>...</td>\n",
       "      <td>6427.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID tpep_pickup_datetime  lag_pickup_count  PU_month  \\\n",
       "0             4  2022-01-01 00:00:00               0.0         1   \n",
       "1             4  2022-01-01 01:00:00              11.0         1   \n",
       "2             4  2022-01-01 02:00:00              10.0         1   \n",
       "3             4  2022-01-01 03:00:00              20.0         1   \n",
       "4             4  2022-01-01 04:00:00               7.0         1   \n",
       "\n",
       "   PU_day_of_month  PU_day_of_week  PU_hour  precip  temp  frost  ...  \\\n",
       "0                1               5        0    0.01  7.99   7.94  ...   \n",
       "1                1               5        1    0.04  7.71   7.69  ...   \n",
       "2                1               5        2    0.13  7.39   7.44  ...   \n",
       "3                1               5        3    0.07  7.21   7.31  ...   \n",
       "4                1               5        4    0.05  7.20   7.30  ...   \n",
       "\n",
       "   landuse_2.0  landuse_3.0  landuse_4.0  landuse_5.0  landuse_6.0  \\\n",
       "0       6427.0       1440.0       9061.0        711.0         94.0   \n",
       "1       6427.0       1440.0       9061.0        711.0         94.0   \n",
       "2       6427.0       1440.0       9061.0        711.0         94.0   \n",
       "3       6427.0       1440.0       9061.0        711.0         94.0   \n",
       "4       6427.0       1440.0       9061.0        711.0         94.0   \n",
       "\n",
       "   landuse_7.0  landuse_8.0  landuse_9.0  landuse_10.0  landuse_11.0  \n",
       "0         81.0       1167.0        806.0         120.0         193.0  \n",
       "1         81.0       1167.0        806.0         120.0         193.0  \n",
       "2         81.0       1167.0        806.0         120.0         193.0  \n",
       "3         81.0       1167.0        806.0         120.0         193.0  \n",
       "4         81.0       1167.0        806.0         120.0         193.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = manhattan_final_prep.drop('PU_count', axis = 1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d80dbf-a3d1-482a-a6b4-d617ca628873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11.0\n",
       "1    10.0\n",
       "2    20.0\n",
       "3     7.0\n",
       "4     6.0\n",
       "Name: PU_count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = manhattan_final_prep['PU_count'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df304c88-8a98-44ba-bb16-464ee25d8df9",
   "metadata": {},
   "source": [
    "# Format Data Part 2: Encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd451c7-63bb-4d60-a463-f2df1f6c32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of hourly data\n",
    "    \n",
    "X_a = X.copy()\n",
    "X_a['PU_hour_sin'] = np.sin(2* np.pi * X_a['PU_hour'] / 24.0)\n",
    "X_a['PU_hour_cos'] = np.cos(2* np.pi * X_a['PU_hour'] / 24.0)\n",
    "\n",
    "# Transformation PU_month, PU_day_of_month, PU_day_of_week\n",
    "\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data\n",
    "\n",
    "X_a = encode(X_a, 'PU_month', 6)\n",
    "X_a = encode(X_a, 'PU_day_of_month', 31)\n",
    "X_a = encode(X_a, 'PU_day_of_week', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c9c7a4-b64a-4f9e-a9d7-dc032ad94aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>lag_pickup_count</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>frost</th>\n",
       "      <th>employment_%</th>\n",
       "      <th>income_high_%</th>\n",
       "      <th>income_med_e</th>\n",
       "      <th>poverty_lev_e</th>\n",
       "      <th>total_pop_e</th>\n",
       "      <th>...</th>\n",
       "      <th>landuse_10.0</th>\n",
       "      <th>landuse_11.0</th>\n",
       "      <th>PU_hour_sin</th>\n",
       "      <th>PU_hour_cos</th>\n",
       "      <th>PU_month_sin</th>\n",
       "      <th>PU_month_cos</th>\n",
       "      <th>PU_day_of_month_sin</th>\n",
       "      <th>PU_day_of_month_cos</th>\n",
       "      <th>PU_day_of_week_sin</th>\n",
       "      <th>PU_day_of_week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.99</td>\n",
       "      <td>7.94</td>\n",
       "      <td>59.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>64059</td>\n",
       "      <td>69075</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.69</td>\n",
       "      <td>59.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>64059</td>\n",
       "      <td>69075</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.44</td>\n",
       "      <td>59.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>64059</td>\n",
       "      <td>69075</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.31</td>\n",
       "      <td>59.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>64059</td>\n",
       "      <td>69075</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.30</td>\n",
       "      <td>59.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>64059</td>\n",
       "      <td>69075</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID  lag_pickup_count  precip  temp  frost  employment_%  \\\n",
       "0             4               0.0    0.01  7.99   7.94          59.4   \n",
       "1             4              11.0    0.04  7.71   7.69          59.4   \n",
       "2             4              10.0    0.13  7.39   7.44          59.4   \n",
       "3             4              20.0    0.07  7.21   7.31          59.4   \n",
       "4             4               7.0    0.05  7.20   7.30          59.4   \n",
       "\n",
       "   income_high_%  income_med_e  poverty_lev_e  total_pop_e  ...  landuse_10.0  \\\n",
       "0           16.6       64909.0          64059        69075  ...         120.0   \n",
       "1           16.6       64909.0          64059        69075  ...         120.0   \n",
       "2           16.6       64909.0          64059        69075  ...         120.0   \n",
       "3           16.6       64909.0          64059        69075  ...         120.0   \n",
       "4           16.6       64909.0          64059        69075  ...         120.0   \n",
       "\n",
       "   landuse_11.0  PU_hour_sin  PU_hour_cos  PU_month_sin  PU_month_cos  \\\n",
       "0         193.0     0.000000     1.000000      0.866025           0.5   \n",
       "1         193.0     0.258819     0.965926      0.866025           0.5   \n",
       "2         193.0     0.500000     0.866025      0.866025           0.5   \n",
       "3         193.0     0.707107     0.707107      0.866025           0.5   \n",
       "4         193.0     0.866025     0.500000      0.866025           0.5   \n",
       "\n",
       "   PU_day_of_month_sin  PU_day_of_month_cos  PU_day_of_week_sin  \\\n",
       "0             0.201299              0.97953           -0.974928   \n",
       "1             0.201299              0.97953           -0.974928   \n",
       "2             0.201299              0.97953           -0.974928   \n",
       "3             0.201299              0.97953           -0.974928   \n",
       "4             0.201299              0.97953           -0.974928   \n",
       "\n",
       "   PU_day_of_week_cos  \n",
       "0           -0.222521  \n",
       "1           -0.222521  \n",
       "2           -0.222521  \n",
       "3           -0.222521  \n",
       "4           -0.222521  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that are not required anymore\n",
    "\n",
    "X_a = X_a.drop(['tpep_pickup_datetime', 'PU_month', 'PU_day_of_month', 'PU_day_of_week', 'PU_hour'], axis = 1)\n",
    "X_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c14f6cd-d2dc-4c43-b8da-20e29bc73c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>lag_pickup_count</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>employment_%</th>\n",
       "      <th>income_med_e</th>\n",
       "      <th>total_pop_e</th>\n",
       "      <th>female_%</th>\n",
       "      <th>age_med_e</th>\n",
       "      <th>landuse_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>landuse_10.0</th>\n",
       "      <th>landuse_11.0</th>\n",
       "      <th>PU_hour_sin</th>\n",
       "      <th>PU_hour_cos</th>\n",
       "      <th>PU_month_sin</th>\n",
       "      <th>PU_month_cos</th>\n",
       "      <th>PU_day_of_month_sin</th>\n",
       "      <th>PU_day_of_month_cos</th>\n",
       "      <th>PU_day_of_week_sin</th>\n",
       "      <th>PU_day_of_week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.99</td>\n",
       "      <td>59.4</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>69075</td>\n",
       "      <td>51.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7.71</td>\n",
       "      <td>59.4</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>69075</td>\n",
       "      <td>51.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>7.39</td>\n",
       "      <td>59.4</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>69075</td>\n",
       "      <td>51.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.21</td>\n",
       "      <td>59.4</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>69075</td>\n",
       "      <td>51.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.20</td>\n",
       "      <td>59.4</td>\n",
       "      <td>64909.0</td>\n",
       "      <td>69075</td>\n",
       "      <td>51.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID  lag_pickup_count  precip  temp  employment_%  income_med_e  \\\n",
       "0             4               0.0    0.01  7.99          59.4       64909.0   \n",
       "1             4              11.0    0.04  7.71          59.4       64909.0   \n",
       "2             4              10.0    0.13  7.39          59.4       64909.0   \n",
       "3             4              20.0    0.07  7.21          59.4       64909.0   \n",
       "4             4               7.0    0.05  7.20          59.4       64909.0   \n",
       "\n",
       "   total_pop_e  female_%  age_med_e  landuse_1.0  ...  landuse_10.0  \\\n",
       "0        69075      51.6       33.5        428.0  ...         120.0   \n",
       "1        69075      51.6       33.5        428.0  ...         120.0   \n",
       "2        69075      51.6       33.5        428.0  ...         120.0   \n",
       "3        69075      51.6       33.5        428.0  ...         120.0   \n",
       "4        69075      51.6       33.5        428.0  ...         120.0   \n",
       "\n",
       "   landuse_11.0  PU_hour_sin  PU_hour_cos  PU_month_sin  PU_month_cos  \\\n",
       "0         193.0     0.000000     1.000000      0.866025           0.5   \n",
       "1         193.0     0.258819     0.965926      0.866025           0.5   \n",
       "2         193.0     0.500000     0.866025      0.866025           0.5   \n",
       "3         193.0     0.707107     0.707107      0.866025           0.5   \n",
       "4         193.0     0.866025     0.500000      0.866025           0.5   \n",
       "\n",
       "   PU_day_of_month_sin  PU_day_of_month_cos  PU_day_of_week_sin  \\\n",
       "0             0.201299              0.97953           -0.974928   \n",
       "1             0.201299              0.97953           -0.974928   \n",
       "2             0.201299              0.97953           -0.974928   \n",
       "3             0.201299              0.97953           -0.974928   \n",
       "4             0.201299              0.97953           -0.974928   \n",
       "\n",
       "   PU_day_of_week_cos  \n",
       "0           -0.222521  \n",
       "1           -0.222521  \n",
       "2           -0.222521  \n",
       "3           -0.222521  \n",
       "4           -0.222521  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop autocorrelated features\n",
    "\n",
    "X_b = X_a.copy()\n",
    "X_b.drop(['frost', 'income_high_%', 'poverty_lev_e', 'age_65_%', 'landuse_7.0'], axis = 1, inplace = True)\n",
    "X_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e81882-33dc-4cb4-8455-855cf361f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in training and testing set \n",
    "\n",
    "X_b_train, X_b_test,y_b_train,y_b_test= train_test_split(X_b,y,test_size=0.2,random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872671c-ef88-42e6-8135-be1fb43a160c",
   "metadata": {},
   "source": [
    "# Performance of different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a61844-e8d9-4409-8c4a-87385c6bf188",
   "metadata": {},
   "source": [
    "**Note:** Regression trees do not require scaling of the features, because scaling does not affect the tree structure. However, linear models or distance-based algorithms like kNN can be sensitive to the feature scale. Therefore, StandardScaling() will be applied in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30e0235-27e2-424b-9d04-7331a650cac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "models_b = [RandomForestRegressor(n_estimators=50), AdaBoostRegressor(), GradientBoostingRegressor(n_estimators=50), HistGradientBoostingRegressor(), SVR(max_iter=1000), KNeighborsRegressor(n_neighbors= 5)]\n",
    "model_names_b = ['RandomForestRegr', 'AdaBoostRegr', 'GradientBoostingRegr', 'HistGradientBoostingRegr', 'SupportVectorRegr', 'KNeighborsRegr']\n",
    "\n",
    "num_cores = 16 # set to the number of available CPU cores\n",
    "\n",
    "# Define StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training and test data\n",
    "X_b_train_scaled = scaler.fit_transform(X_b_train)\n",
    "X_b_test_scaled = scaler.transform(X_b_test)\n",
    "\n",
    "# Define the function to perform regression\n",
    "def perform_regression(model, X_train, y_train, X_test, y_test):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    mse = mean_squared_error(test_pred, y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mse, rmse\n",
    "\n",
    "# Apply the models to the scaled data in parallel\n",
    "mse_b, rmse_b = zip(*Parallel(n_jobs=num_cores)(delayed(perform_regression)(model, X_b_train_scaled, y_b_train, X_b_test_scaled, y_b_test) for model in models_b))\n",
    "\n",
    "d_b = {'Modelling Algo': model_names_b, 'MSE': mse_b, 'RMSE': rmse_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "700ef489-100c-40d3-a435-45c6797e0a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Modelling Algo           MSE        RMSE\n",
      "0          RandomForestRegr    192.657725   13.880120\n",
      "1              AdaBoostRegr   1546.989202   39.331784\n",
      "2      GradientBoostingRegr    336.043164   18.331480\n",
      "3  HistGradientBoostingRegr    209.044292   14.458364\n",
      "4         SupportVectorRegr  16249.008006  127.471597\n",
      "5            KNeighborsRegr    401.831450   20.045734\n"
     ]
    }
   ],
   "source": [
    "modelling_algo = pd.DataFrame(d_b)\n",
    "print(modelling_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e16db05-1d07-41b6-becd-e7e912aea369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='RMSE', ylabel='Modelling Algo'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelling_algo_sorted = modelling_algo.sort_values('RMSE')\n",
    "\n",
    "sns.barplot(y='Modelling Algo',x='RMSE',data= modelling_algo_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cad85d-ba04-47e4-8dc9-9147bc61990c",
   "metadata": {},
   "source": [
    "RandomForestRegr, GradientBoostingRegr and HistGradientBoostingRegr are the most promising algorithms. They well be tuned in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0f974-2ff4-4b37-bf11-0f5d9dfce458",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5452565-7e70-4488-90b9-c156f0b90c03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "A random forest is an estimator that fits a number of trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with *max_samples* parameter if *bootstrap = True* (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "There are important hyperparameters to consider:\n",
    "\n",
    "**n_estimators:** \n",
    "- number of trees in the forest\n",
    "- default = 100\n",
    "\n",
    "**criterion:**\n",
    "- the function to measure the quality of a split \n",
    "- default = squared error for the mean squared error \n",
    "\n",
    "**max_features:**\n",
    "- number of features to consider when looking for the best split \n",
    "\n",
    "**max_depth:**\n",
    "- maximum number of levels in the tree\n",
    "- default = None \n",
    "- if None, then nodes are expanded until all leaves are pure / all leaves contain less than min_sample_split samples\n",
    "\n",
    "**min_samples_split:**\n",
    "- minimum number of samples required to split a node\n",
    "- If “auto”, then max_features=n_features.\n",
    "- If “sqrt”, then max_features=sqrt(n_features).\n",
    "- If “log2”, then max_features=log2(n_features).\n",
    "- If None or 1.0, then max_features=n_features.\n",
    "- default = 1.0 \n",
    "- Note: The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3. \n",
    "\n",
    "**min_samples_leaf:**\n",
    "- minimum number of samples requiret at each leaf node\n",
    "- a split point at any depth will onyl be considered it it leaves at least *min_samples_leaf* training samples in each of the left and right branches \n",
    "- default = 1 \n",
    "\n",
    "**bootstrap:**\n",
    "- method of selecting samples for training each tree\n",
    "- default = True\n",
    "- if False, the whole dataset is used to build each tree \n",
    "\n",
    "**n_jobs:**\n",
    "- the number of jobs to run in parallel\n",
    "\n",
    "**Source:**\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f9f48-d5e3-409d-a332-68e755613fcf",
   "metadata": {},
   "source": [
    "### Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a65d98-dde1-45ff-aa57-a15b32a6261b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100.,  200.,  300.,  400.,  500.,  600.,  700.,  800.,  900.,\n",
       "       1000.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(start = 100, stop = 1000, num = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bf5067-4ebe-41f6-b74b-58a3b3467f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter tuning space\n",
    "\n",
    "n_estimators = [int (x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, 10)]\n",
    "min_samples_split = [1,3,5,7,9,11]\n",
    "min_samples_leaf = [1,2,4,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a31a2696-8989-407b-83a7-a9420f0582d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'min_samples_split': [1, 3, 5, 7, 9, 11], 'min_samples_leaf': [1, 2, 4, 6, 8]}\n"
     ]
    }
   ],
   "source": [
    "# Create the param grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split, \n",
    "                'min_samples_leaf': min_samples_leaf, \n",
    "                }\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190e3908-a57e-421a-8d8c-7a015d8d36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73db61c1-463c-45e8-b0cb-61f279031286",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.5s\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=8, min_samples_split=1, n_estimators=700; total time=   0.6s\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=8, min_samples_split=1, n_estimators=700; total time=   0.5s\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=8, min_samples_split=1, n_estimators=700; total time=   0.5s\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=700; total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=9, n_estimators=700; total time= 5.9min\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time= 4.4min\n",
      "[CV] END max_depth=80, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=700; total time= 4.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=9, n_estimators=700; total time= 5.8min\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time= 4.5min\n",
      "[CV] END max_depth=80, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=700; total time= 4.4min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 7.1min\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time= 4.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 3.4min\n",
      "[CV] END max_depth=60, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=800; total time= 6.2min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 7.1min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=20.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1000; total time= 9.0min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 2.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 3.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1000; total time= 9.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=200; total time=  52.6s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=800; total time= 4.0min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 2.9min\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=900; total time=37.3min\n",
      "[CV] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=300; total time=12.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=300; total time= 2.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=300; total time= 2.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=600; total time= 3.8min\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=900; total time=36.9min\n",
      "[CV] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=300; total time=12.0min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=800; total time= 5.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=600; total time= 3.8min\n",
      "[CV] END max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=32.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 2.9min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=600; total time=24.9min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=6, min_samples_split=9, n_estimators=400; total time= 3.1min\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=300; total time= 2.5min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=11, n_estimators=600; total time=22.5min\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=700; total time=   0.5s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=700; total time=   0.5s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=700; total time=   0.5s\n",
      "[CV] END max_depth=60, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=800; total time= 6.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1000; total time= 8.9min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=11, n_estimators=700; total time=25.1min\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=900; total time= 7.2min\n",
      "[CV] END max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=900; total time=37.1min\n",
      "[CV] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=7, n_estimators=300; total time=12.1min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=800; total time= 5.3min\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=900; total time= 7.3min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=300; total time= 2.2min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=8, min_samples_split=1, n_estimators=600; total time=   0.4s\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=8, min_samples_split=1, n_estimators=600; total time=   0.5s\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=8, min_samples_split=1, n_estimators=600; total time=   0.4s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1000; total time= 6.3min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=700; total time= 4.4min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=700; total time= 4.4min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=21.2min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=11, n_estimators=700; total time=26.0min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=100; total time=  34.6s\n",
      "[CV] END max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=100; total time= 4.1min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=400; total time= 3.3min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1000; total time= 6.4min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 7.1min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=8, min_samples_split=9, n_estimators=600; total time=20.8min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=200; total time=  52.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=11, n_estimators=700; total time=25.3min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=900; total time= 7.2min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=400; total time= 3.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=9, n_estimators=1000; total time= 6.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=9, n_estimators=700; total time= 5.8min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=11, n_estimators=900; total time=33.5min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time=39.2min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.6min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000; total time= 7.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=800; total time= 5.5min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=200; total time=  55.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=800; total time= 4.5min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=6, min_samples_split=9, n_estimators=400; total time= 3.4min\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=300; total time= 2.6min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=11, n_estimators=600; total time=24.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=900; total time= 4.2min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=400; total time= 2.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.6min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=10.9min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=2, min_samples_split=9, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=300; total time= 2.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=900; total time= 7.3min\n",
      "[CV] END max_depth=90, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=90, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=90, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=300; total time=   0.3s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=6, min_samples_split=1, n_estimators=600; total time=   0.4s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=9, n_estimators=100; total time=  51.6s\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=9, n_estimators=100; total time=  51.9s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=6, min_samples_split=1, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time= 3.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=900; total time= 5.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=900; total time= 7.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=600; total time= 3.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=400; total time= 2.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=900; total time= 5.9min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=700; total time= 6.4min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=400; total time= 2.7min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=10.8min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=300; total time= 2.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=900; total time= 6.0min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=400; total time= 3.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=  48.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=400; total time= 3.2min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=9, n_estimators=100; total time=  52.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=100; total time=  22.3s\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time= 3.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=900; total time= 6.0min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=400; total time= 3.2min\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=300; total time= 2.1min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=700; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=900; total time= 7.7min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=600; total time= 4.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=800; total time= 5.7min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=700; total time= 5.6min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=  48.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=  39.6s\n",
      "[CV] END max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=32.5min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=600; total time=25.1min\n",
      "[CV] END max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=600; total time= 4.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=900; total time= 3.9min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=500; total time= 3.2min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=10.6min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=300; total time= 2.3min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=900; total time= 7.3min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=900; total time= 7.2min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=700; total time= 4.4min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=700; total time= 4.3min\n",
      "[CV] END max_depth=80, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=700; total time= 4.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 3.6min\n",
      "[CV] END max_depth=60, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=800; total time= 6.4min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time= 1.9min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time= 1.9min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=200; total time= 1.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=800; total time= 4.1min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=300; total time= 2.5min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  60.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=800; total time= 5.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=300; total time= 2.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=600; total time= 3.8min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=100; total time=  27.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=7, n_estimators=100; total time=  34.3s\n",
      "[CV] END max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=100; total time= 4.1min\n",
      "[CV] END max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=600; total time= 4.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=900; total time= 7.2min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=200; total time= 1.3min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000; total time= 7.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=800; total time= 5.2min\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=700; total time= 5.0min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=11, n_estimators=900; total time=33.1min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time=40.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=400; total time= 2.1min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=2, min_samples_split=9, n_estimators=400; total time= 2.9min\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=700; total time= 5.2min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=2, min_samples_split=11, n_estimators=400; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=900; total time= 4.0min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=6, min_samples_split=7, n_estimators=400; total time= 2.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000; total time= 7.8min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=400; total time= 2.1min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=2, min_samples_split=9, n_estimators=400; total time= 2.9min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=900; total time= 7.1min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=7, n_estimators=100; total time= 3.5min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=6, min_samples_split=9, n_estimators=400; total time= 3.1min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=7, n_estimators=400; total time= 3.1min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time=41.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=900; total time= 6.4min\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1000; total time=   1.4s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1000; total time=   1.1s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=7, n_estimators=100; total time= 3.7min\n",
      "[CV] END max_depth=70, max_features=log2, min_samples_leaf=8, min_samples_split=7, n_estimators=700; total time= 4.5min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=2, min_samples_split=11, n_estimators=900; total time=34.0min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=11, n_estimators=600; total time=23.0min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=300; total time= 2.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=900; total time= 3.9min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=900; total time= 7.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=600; total time= 3.8min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=100; total time=  22.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=100; total time=  29.7s\n",
      "[CV] END max_depth=90, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=70, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=300; total time= 2.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=900; total time= 5.7min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=7, n_estimators=100; total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "42 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
      "    for i, t in enumerate(trees)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 289, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
      "    % self.min_samples_split\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.9601571  0.96616055 0.96476182 0.96747798 0.96475154        nan\n",
      "        nan 0.96037361 0.96455424 0.96433903 0.96354611 0.96029545\n",
      " 0.96775524        nan        nan 0.9660945  0.96797325 0.96766924\n",
      " 0.92570081        nan 0.93965486 0.96440941 0.96580408 0.96321584\n",
      " 0.964548   0.96469847 0.9661785  0.9646367  0.96323309 0.96448304\n",
      " 0.96476717 0.9382216         nan 0.96214063 0.96469279 0.96032269\n",
      "        nan 0.96616793 0.93905575 0.96438962 0.9650688  0.96332281\n",
      " 0.9666282  0.96579559        nan 0.96793439 0.92587297        nan\n",
      "        nan 0.96037402 0.92616921 0.96623534 0.96210244 0.96190799\n",
      " 0.96668194 0.96624717 0.96353615 0.96201442 0.96325601 0.96462872\n",
      " 0.96190857        nan        nan 0.96666241 0.92560299        nan\n",
      " 0.9670226  0.96480231 0.93935916 0.96459669 0.96208817 0.96530363\n",
      " 0.96180355 0.96622742 0.96021858 0.96467728 0.96645657        nan\n",
      " 0.96449407 0.96603499]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=32.5min\n",
      "[CV] END max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=400; total time= 3.0min\n",
      "[CV] END max_depth=40, max_features=auto, min_samples_leaf=2, min_samples_split=3, n_estimators=600; total time=25.0min\n",
      "[CV] END max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=11, n_estimators=600; total time= 4.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=900; total time= 3.9min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=500; total time= 3.3min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=200; total time= 1.4min\n",
      "[CV] END max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=1000; total time=31.2min\n",
      "[CV] END max_depth=60, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=100; total time= 4.0min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=300; total time= 2.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=900; total time= 4.0min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=900; total time= 7.3min\n",
      "[CV] END max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=1000; total time=30.5min\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=300; total time= 2.1min\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=11, n_estimators=300; total time= 2.2min\n",
      "[CV] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=700; total time= 6.6min\n",
      "[CV] END max_depth=60, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=500; total time= 3.4min\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=6, min_samples_split=9, n_estimators=200; total time= 1.4min\n",
      "[CV] END max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=9, n_estimators=1000; total time=31.9min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=80,\n",
       "                   n_jobs=16,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [1, 3, 5, 7, 9,\n",
       "                                                              11],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000]},\n",
       "                   random_state=22, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with RandomizedSearchCV\n",
    "\n",
    "rf_random_cv = RandomizedSearchCV (estimator = rf, \n",
    "                                     param_distributions = random_grid, \n",
    "                                     n_iter = 80, \n",
    "                                     cv = 3, \n",
    "                                     verbose = 2, \n",
    "                                     n_jobs = 16, \n",
    "                                     random_state = 22)\n",
    "\n",
    "# Fit the randomized model\n",
    "\n",
    "rf_random_cv.fit(X_b_train, y_b_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6eccc-b20d-483b-a074-06583990e72c",
   "metadata": {},
   "source": [
    "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=80,\n",
    "                   n_jobs=16,\n",
    "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
    "                                                      70, 80, 90, 100],\n",
    "                                        'max_features': ['auto', 'sqrt',\n",
    "                                                         'log2'],\n",
    "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "                                        'min_samples_split': [1, 3, 5, 7, 9,\n",
    "                                                              11],\n",
    "                                        'n_estimators': [100, 200, 300, 400,\n",
    "                                                         500, 600, 700, 800,\n",
    "                                                         900, 1000]},\n",
    "                   random_state=22, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f0e48b3-d3bf-458b-916a-fb4eedda9977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  169.12300863120038\n",
      "RMSE:  13.004730240616311\n",
      "R-squared:  0.9698103963827789\n"
     ]
    }
   ],
   "source": [
    "# Create new RF model with best hyperparams\n",
    "\n",
    "rf_best_rand_1 = RandomForestRegressor(n_estimators = 1000,\n",
    "                                       min_samples_split = 3,\n",
    "                                       min_samples_leaf = 2,\n",
    "                                       max_features = 'sqrt',\n",
    "                                       max_depth = 80,\n",
    "                                       random_state = 0, \n",
    "                                       n_jobs = 32)\n",
    "\n",
    "# Fit the model to the training data \n",
    "rf_best_rand_1.fit(X_b_train, y_b_train)\n",
    "\n",
    "# Evaluate the performance on the test data\n",
    "\n",
    "y_pred_rf_1 = rf_best_rand_1.predict(X_b_test)\n",
    "mse_rf_1 = mean_squared_error(y_b_test, y_pred_rf_1)\n",
    "rmse_rf_1 = np.sqrt(mse_rf_1)\n",
    "r2_rf_1 = r2_score(y_b_test, y_pred_rf_1)\n",
    "\n",
    "print(\"MSE: \", mse_rf_1)\n",
    "print(\"RMSE: \", rmse_rf_1)\n",
    "print(\"R-squared: \", r2_rf_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6318d6-1576-4547-baaf-88b72afb641c",
   "metadata": {},
   "source": [
    "**Model with different hyperparameter tuning space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cf9bdc1-1869-481f-a7d1-8dc77ad7c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [1000, 1055, 1111, 1166, 1222, 1277, 1333, 1388, 1444, 1500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 15, 20, 25, 30], 'min_samples_split': [11, 13, 15, 18, 20], 'min_samples_leaf': [1, 2, 4, 6, 8]}\n"
     ]
    }
   ],
   "source": [
    "# Create hyperparameter tuning space 2\n",
    "\n",
    "n_estimators_2 = [int (x) for x in np.linspace(start = 1000, stop = 1500, num = 10)]\n",
    "max_features_2 = ['auto', 'sqrt', 'log2']\n",
    "max_depth_2 = [int(x) for x in np.linspace(10, 30, 5)]\n",
    "min_samples_split_2 = [11,13,15,18,20]\n",
    "min_samples_leaf_2 = [1,2,4,6,8]\n",
    "\n",
    "\n",
    "# Create the param grid\n",
    "\n",
    "random_grid_2 = {'n_estimators': n_estimators_2,\n",
    "                'max_features': max_features_2,\n",
    "                'max_depth': max_depth_2,\n",
    "                'min_samples_split': min_samples_split_2, \n",
    "                'min_samples_leaf': min_samples_leaf_2, \n",
    "                }\n",
    "\n",
    "print(random_grid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0985abd5-405a-4898-b676-84f6795b30e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1111; total time= 6.9min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=6, min_samples_split=20, n_estimators=1388; total time=10.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1111; total time= 6.8min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=11, n_estimators=1166; total time=10.8min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1111; total time= 6.8min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=6, min_samples_split=20, n_estimators=1388; total time=10.9min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1166; total time= 8.5min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=15, n_estimators=1222; total time= 9.5min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1166; total time= 8.5min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=6, min_samples_split=20, n_estimators=1388; total time=10.6min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=1055; total time= 9.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=11, n_estimators=1333; total time=12.0min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=13, n_estimators=1166; total time=10.6min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=11, n_estimators=1333; total time=11.9min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=13, n_estimators=1166; total time=10.6min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=13, n_estimators=1444; total time=12.8min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=1333; total time= 8.8min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=15, n_estimators=1222; total time= 9.6min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=20, n_estimators=1277; total time=10.9min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=1055; total time= 9.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=11, n_estimators=1333; total time=11.8min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=20, n_estimators=1277; total time=10.5min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=13, n_estimators=1166; total time=10.6min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=13, n_estimators=1444; total time=12.9min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=15, n_estimators=1500; total time=11.4min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=1, min_samples_split=15, n_estimators=1444; total time= 9.4min\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1111; total time= 8.2min\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=6, min_samples_split=18, n_estimators=1333; total time= 9.4min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=1333; total time= 8.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1500; total time= 9.2min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1222; total time=10.9min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=15, n_estimators=1500; total time=11.3min\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=6, min_samples_split=18, n_estimators=1333; total time= 9.5min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=13, n_estimators=1166; total time=42.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1055; total time= 9.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=6, min_samples_split=15, n_estimators=1000; total time= 8.6min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=13, n_estimators=1166; total time=42.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1055; total time= 9.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=6, min_samples_split=15, n_estimators=1000; total time= 8.7min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=6, min_samples_split=15, n_estimators=1333; total time=51.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=13, n_estimators=1111; total time= 5.6min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1055; total time= 7.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=18, n_estimators=1222; total time=10.4min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1055; total time= 7.1min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=18, n_estimators=1166; total time=47.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=18, n_estimators=1222; total time=10.5min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1055; total time= 7.1min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=20, n_estimators=1222; total time=47.3min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=20, n_estimators=1222; total time=47.6min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=13, n_estimators=1111; total time=10.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=1277; total time= 6.5min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=6, min_samples_split=15, n_estimators=1333; total time=51.6min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=6, min_samples_split=15, n_estimators=1000; total time= 8.7min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=1277; total time= 6.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=11, n_estimators=1277; total time= 6.4min\n",
      "[CV] END max_depth=25, max_features=auto, min_samples_leaf=6, min_samples_split=11, n_estimators=1277; total time=49.1min\n",
      "[CV] END max_depth=25, max_features=auto, min_samples_leaf=6, min_samples_split=11, n_estimators=1277; total time=49.5min\n",
      "[CV] END max_depth=25, max_features=auto, min_samples_leaf=6, min_samples_split=11, n_estimators=1277; total time=49.4min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=2, min_samples_split=13, n_estimators=1166; total time=42.5min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=11, n_estimators=1055; total time=37.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=11, n_estimators=1166; total time=10.7min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=13, n_estimators=1444; total time=12.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=15, n_estimators=1500; total time=11.3min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=1055; total time= 9.0min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=11, n_estimators=1055; total time=36.7min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=11, n_estimators=1055; total time=36.6min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=6, min_samples_split=11, n_estimators=1333; total time= 8.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1500; total time= 9.2min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=18, n_estimators=1166; total time=32.9min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=20, n_estimators=1111; total time=32.1min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=15, n_estimators=1444; total time=56.5min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=13, n_estimators=1055; total time=31.8min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=18, n_estimators=1166; total time=32.7min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=20, n_estimators=1111; total time=33.4min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=18, n_estimators=1166; total time=46.6min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=20, n_estimators=1166; total time=38.3min\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=18, n_estimators=1166; total time=32.7min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=20, n_estimators=1111; total time=34.3min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=15, n_estimators=1055; total time= 9.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1500; total time= 9.1min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1222; total time=10.8min\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1111; total time= 8.1min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=1055; total time= 8.7min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=18, n_estimators=1500; total time=44.4min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=8, min_samples_split=18, n_estimators=1222; total time=46.5min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=20, n_estimators=1166; total time=38.9min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=20, n_estimators=1166; total time= 8.6min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=8, min_samples_split=15, n_estimators=1222; total time= 9.6min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=15, n_estimators=1222; total time=10.9min\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=2, min_samples_split=15, n_estimators=1111; total time= 8.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=18, n_estimators=1055; total time= 9.0min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=18, n_estimators=1500; total time=44.0min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=8, min_samples_split=18, n_estimators=1222; total time=46.6min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=20, n_estimators=1166; total time=39.2min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=8, min_samples_split=18, n_estimators=1222; total time=46.3min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=18, n_estimators=1500; total time=44.6min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=6, min_samples_split=15, n_estimators=1333; total time=51.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=13, n_estimators=1111; total time= 5.7min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=13, n_estimators=1111; total time=29.5min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=15, n_estimators=1444; total time=56.4min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=13, n_estimators=1055; total time=31.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=11, n_estimators=1166; total time=10.8min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=20, n_estimators=1222; total time=48.1min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=13, n_estimators=1111; total time=30.0min\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=1, min_samples_split=18, n_estimators=1166; total time=46.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=18, n_estimators=1222; total time=10.6min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=6, min_samples_split=13, n_estimators=1055; total time=31.8min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=4, min_samples_split=20, n_estimators=1277; total time=10.8min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=1, min_samples_split=15, n_estimators=1444; total time= 9.5min\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=6, min_samples_split=18, n_estimators=1333; total time= 9.6min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=13, n_estimators=1111; total time=10.3min\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_leaf=4, min_samples_split=13, n_estimators=1111; total time=29.9min\n",
      "[CV] END max_depth=25, max_features=auto, min_samples_leaf=6, min_samples_split=20, n_estimators=1500; total time=37.6min\n",
      "[CV] END max_depth=15, max_features=log2, min_samples_leaf=1, min_samples_split=15, n_estimators=1444; total time= 9.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=11, n_estimators=1055; total time= 9.4min\n",
      "[CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=13, n_estimators=1111; total time=10.2min\n",
      "[CV] END max_depth=25, max_features=auto, min_samples_leaf=6, min_samples_split=20, n_estimators=1500; total time=39.0min\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=15, n_estimators=1444; total time=56.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=13, n_estimators=1111; total time= 5.8min\n",
      "[CV] END max_depth=25, max_features=auto, min_samples_leaf=6, min_samples_split=20, n_estimators=1500; total time=37.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=40,\n",
       "                   n_jobs=32,\n",
       "                   param_distributions={'max_depth': [10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [11, 13, 15, 18,\n",
       "                                                              20],\n",
       "                                        'n_estimators': [1000, 1055, 1111, 1166,\n",
       "                                                         1222, 1277, 1333, 1388,\n",
       "                                                         1444, 1500]},\n",
       "                   random_state=22, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with RandomizedSearchCV\n",
    "\n",
    "rf_random_cv_2 = RandomizedSearchCV (estimator = rf, \n",
    "                                     param_distributions = random_grid_2, \n",
    "                                     n_iter = 40, \n",
    "                                     cv = 3, \n",
    "                                     verbose = 2, \n",
    "                                     n_jobs = 32, \n",
    "                                     random_state = 22)\n",
    "\n",
    "# Fit the randomized model\n",
    "\n",
    "rf_random_cv_2.fit(X_b_train, y_b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d3b9c63-c43f-4f80-b3dc-2733ce49b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1166, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}\n"
     ]
    }
   ],
   "source": [
    "best_random_grid_2 = rf_random_cv_2.best_params_\n",
    "print(best_random_grid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e038e947-1827-43b8-8170-74252b404624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  172.75974011996368\n",
      "RMSE:  13.143809954498114\n",
      "R-squared:  0.9691612151566604\n"
     ]
    }
   ],
   "source": [
    "# Create new RF model with best hyperparams\n",
    "\n",
    "rf_best_rand_2 = RandomForestRegressor(n_estimators = best_random_grid_2 ['n_estimators'],\n",
    "                                       min_samples_split = best_random_grid_2 ['min_samples_split'],\n",
    "                                       min_samples_leaf = best_random_grid_2 ['min_samples_leaf'],\n",
    "                                       max_features = best_random_grid_2 ['max_features'],\n",
    "                                       max_depth = best_random_grid_2['max_depth'],\n",
    "                                       random_state = 0, \n",
    "                                       n_jobs = 32)\n",
    "\n",
    "# Fit the model to the training data \n",
    "rf_best_rand_2.fit(X_b_train, y_b_train)\n",
    "\n",
    "# Evaluate the performance on the test data\n",
    "\n",
    "y_pred_rf_2 = rf_best_rand_2.predict(X_b_test)\n",
    "mse_rf_2 = mean_squared_error(y_b_test, y_pred_rf_2)\n",
    "rmse_rf_2 = np.sqrt(mse_rf_2)\n",
    "r2_rf_2 = r2_score(y_b_test, y_pred_rf_2)\n",
    "\n",
    "print(\"MSE: \", mse_rf_2)\n",
    "print(\"RMSE: \", rmse_rf_2)\n",
    "print(\"R-squared: \", r2_rf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce8f56-d3f7-48fa-93e0-9510d4deee65",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec15a754-cbd1-493a-9f29-53b34b948170",
   "metadata": {},
   "source": [
    "Select the best performing input parameters from RandomizedSearchCV and give some additional values. No option of iteration in GridSearch CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "939cc35e-1f89-4830-a032-cb0318bece34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters from randomized search\n",
    "best_params_rand = {'n_estimators': 1000, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 80}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1ecdf60-efd3-44f4-9cd2-0b51bd9215bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [800, 900, 1000, 1100, 1200], 'max_depth': [80], 'min_samples_split': [1, 2, 3, 4, 5], 'min_samples_leaf': [2, 4, 6], 'max_features': ['sqrt']}\n"
     ]
    }
   ],
   "source": [
    "grid_search = {\n",
    "    'n_estimators': [best_params_rand['n_estimators']-200,\n",
    "                    best_params_rand['n_estimators']-100,\n",
    "                    best_params_rand['n_estimators'],\n",
    "                    best_params_rand['n_estimators']+100,\n",
    "                    best_params_rand['n_estimators']+200,\n",
    "                    ],\n",
    "    'max_depth': [best_params_rand['max_depth']],\n",
    "    'min_samples_split': [best_params_rand['min_samples_split']-2,\n",
    "                         best_params_rand['min_samples_split']-1,\n",
    "                         best_params_rand['min_samples_split'],\n",
    "                         best_params_rand['min_samples_split']+1,\n",
    "                         best_params_rand['min_samples_split']+2,\n",
    "                         ],\n",
    "    'min_samples_leaf': [best_params_rand['min_samples_leaf'],\n",
    "                        best_params_rand['min_samples_leaf']+2,\n",
    "                        best_params_rand['min_samples_leaf']+4,\n",
    "                        ],\n",
    "    'max_features': [best_params_rand['max_features']],\n",
    "}\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d5c8bd6-3103-467d-9a57-ac0e046b708e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 75 candidates, totalling 150 fits\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time= 9.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000; total time= 7.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1100; total time= 9.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1100; total time= 8.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1200; total time=   1.0s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 6.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 8.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1100; total time= 9.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=900; total time= 6.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1200; total time= 8.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=800; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1100; total time= 9.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1200; total time= 8.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1100; total time= 9.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000; total time= 7.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1100; total time= 7.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800; total time= 6.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1200; total time=10.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1100; total time= 7.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 467, in fit\n",
      "    for i, t in enumerate(trees)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 289, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 289, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1320, in fit\n",
      "    X_idx_sorted=X_idx_sorted,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 254, in fit\n",
      "    % self.min_samples_split\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.9664398\n",
      " 0.9664654  0.96654398 0.96645976 0.96648709 0.96642095 0.96650926\n",
      " 0.96649542 0.96653111 0.96647797 0.96643429 0.96647524 0.96648138\n",
      " 0.96647054 0.96652277 0.96632999 0.96638298 0.96632705 0.96637526\n",
      " 0.96636523        nan        nan        nan        nan        nan\n",
      " 0.96446863 0.96445825 0.96457189 0.96454267 0.964557   0.96451525\n",
      " 0.96451672 0.96456215 0.96450434 0.96456409 0.96454284 0.96450529\n",
      " 0.96450347 0.96452697 0.9645283  0.96456213 0.96443632 0.9645662\n",
      " 0.96453602 0.96447281        nan        nan        nan        nan\n",
      "        nan 0.96271829 0.96276182 0.96278624 0.96271881 0.96280828\n",
      " 0.962689   0.9628081  0.96279403 0.9628224  0.96274027 0.96274507\n",
      " 0.96279543 0.96276507 0.96273594 0.96279409 0.96270799 0.96268048\n",
      " 0.96274718 0.96275549 0.9628242 ]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=10.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=900; total time= 6.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200; total time= 7.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1200; total time=10.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1200; total time= 8.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1000; total time= 6.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1100; total time=   1.0s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=10.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=900; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200; total time= 8.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1200; total time=10.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1200; total time= 9.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1000; total time= 6.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1000; total time= 8.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=800; total time= 6.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 5.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1100; total time= 6.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1200; total time=   1.0s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time= 6.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 8.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=900; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=800; total time= 4.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=800; total time= 5.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=800; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=900; total time= 7.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=800; total time=   0.6s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=900; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=1100; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=800; total time= 6.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time= 7.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1100; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=900; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time= 8.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1100; total time= 8.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=800; total time=   0.6s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=800; total time=   0.6s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=900; total time=   0.6s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=900; total time=   0.6s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1100; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1100; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=800; total time= 5.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=900; total time= 5.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=10.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=800; total time= 6.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=1, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=800; total time= 5.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=900; total time= 5.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 8.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=800; total time= 6.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 6.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200; total time= 6.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800; total time= 6.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 7.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1100; total time= 8.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1000; total time= 5.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=800; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=900; total time= 7.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=900; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=1100; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=1, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=800; total time= 6.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time= 7.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200; total time= 7.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=900; total time= 7.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=900; total time= 6.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time= 8.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=800; total time= 5.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=1100; total time=   1.0s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=10.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=800; total time= 6.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=900; total time= 6.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=800; total time= 5.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time= 6.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=900; total time= 7.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1100; total time= 8.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1000; total time= 5.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=1, n_estimators=900; total time=   0.8s\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time= 8.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time= 9.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=800; total time= 5.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=900; total time= 5.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=900; total time= 7.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=900; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time= 8.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=900; total time= 5.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time= 7.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1200; total time= 9.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1000; total time= 6.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1000; total time= 4.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1100; total time= 9.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=900; total time= 6.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1100; total time= 7.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1000; total time= 5.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=900; total time= 6.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1100; total time= 5.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=900; total time= 7.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 7.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time= 7.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1100; total time= 6.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=800; total time= 6.8min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1100; total time= 9.2min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1100; total time= 8.0min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1100; total time= 5.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=1000; total time= 8.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time= 9.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=800; total time= 5.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1200; total time= 6.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=900; total time= 7.9min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time= 7.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000; total time= 7.5min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1200; total time= 6.4min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 8.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=1100; total time= 8.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1000; total time= 7.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1100; total time= 5.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=900; total time= 6.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1200; total time= 5.6min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1100; total time= 9.7min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1100; total time= 8.3min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=900; total time= 6.1min\n",
      "[CV] END max_depth=80, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1200; total time= 5.9min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestRegressor(), n_jobs=32,\n",
       "             param_grid={'max_depth': [80], 'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [2, 4, 6],\n",
       "                         'min_samples_split': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [800, 900, 1000, 1100, 1200]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid_search to the training data \n",
    "\n",
    "rf_grid_search_cv = GridSearchCV(estimator = rf, param_grid = grid_search, cv = 2, n_jobs = 32, verbose = 2)\n",
    "rf_grid_search_cv.fit(X_b_train, y_b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38b5392c-aa6b-461a-ad0e-cea011acda92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.28410767e-04, 1.97383323e+01, 2.64028426e-01, ...,\n",
       "       1.08291933e+01, 2.57292021e+01, 1.18528025e+01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "\n",
    "rf_grid_search_cv.predict(X_b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9b6573d-6c34-4150-9450-d71eda80404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 80, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "best_grid = rf_grid_search_cv.best_params_\n",
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a196a1d4-4cad-4d67-bc62-10d26d1aa185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  169.12300863120038\n",
      "RMSE:  13.004730240616311\n",
      "R-squared:  0.9698103963827789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create a new Random Forest model with the best hyperparameters\n",
    "rf_grid = RandomForestRegressor(n_estimators=best_grid['n_estimators'], \n",
    "                                max_depth= best_grid['max_depth'], \n",
    "                                max_features= best_grid['max_features'],\n",
    "                                min_samples_leaf= best_grid['min_samples_leaf'], \n",
    "                                min_samples_split= best_grid['min_samples_split'],\n",
    "                                random_state=0, \n",
    "                                n_jobs = 32)\n",
    "\n",
    "# Fit the model to the entire training set\n",
    "rf_grid.fit(X_b_train, y_b_train)\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "y_b_pred_grid = rf_grid.predict(X_b_test)\n",
    "\n",
    "mse_grid = mean_squared_error(y_b_test, y_b_pred_grid)\n",
    "rmse_grid = np.sqrt(mse_grid)\n",
    "r2_grid = r2_score(y_b_test, y_b_pred_grid)\n",
    "print(\"MSE: \", mse_grid)\n",
    "print(\"RMSE: \", rmse_grid)\n",
    "print(\"R-squared: \", r2_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22f251-6598-4bca-95fd-fe4dcd9a5217",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb5fec-387a-49ee-b8f6-7598d89e6390",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradient Boosting Regression Tree (=GBRT)\n",
    "* this estimator builds an additive model in a forward stage-wise fashion\n",
    "* it allows for the optimization of arbitrary differentiable loss functions \n",
    "* in each stage a regression tree is fit on the negative gradient of the given loss function \n",
    "<br> \n",
    "\n",
    "**There are 8 important hyperparameters to consider:** \n",
    "\n",
    "**loss function**: <br>\n",
    "* The type of residual error / loss function that will be used\n",
    "* default = squared error <br>\n",
    "\n",
    "**criterion**: <br>\n",
    "* the function to measure the quality of a split \n",
    "* default = friedman_mse for the mean squared error with improvement score by friedmann <br>\n",
    "\n",
    "**subsample**: <br>\n",
    "* the proportion of cases to be randomly sampled (without replacement) for each tree\n",
    "* values are between 0.0 and 1.0\n",
    "* setting this to 1 uses all the cases in the training set \n",
    "* if smaller than 1.0 this results in stochastic gradient boosting (reduction of variance and increase in bias)\n",
    "* it interacts with the parameter n_estimator\n",
    "* default = 1.0 <br>\n",
    "\n",
    "**learning rate**: <br>\n",
    "* This is a number between 0.0 and infinity, which model weights are multiplied to give their final weight. \n",
    "* It shrinks the contribution of each tree by *learning_rate*. \n",
    "* The smaller the learning rate, the smaller steps towards the optimal solution. \n",
    "* Pro: Preventing the ensemble from learning too quickly prevents overfitting\n",
    "* Con: longer training times as a smaller learning rate will require more trees to be added to the ensemble to achieve the same level of performance\n",
    "* default = 0.1 <br>\n",
    "\n",
    "**n_estimators**: <br>\n",
    "* the number of boosting stages to perform (between 1 and infinity)\n",
    "* equivalent to the number of weak learners to be used in the ensemble\n",
    "* large number usually results in better performance \n",
    "* Note: there is a trade-off between *learning_rate* and *n_estimators*\n",
    "* default = 100\n",
    "\n",
    "**min_impurity_decrease**: <br>\n",
    "* a node will be split if this split induces a decrease of the impurity greater than or equal to this value (between 0.0 and infinity)\n",
    "* weighted impurity decrease equation:\n",
    "* N_t / N * (impurity - N_t_R / N_t * right_impurity - N_t_L / N_t * left_impurity)\n",
    "\n",
    "**max_depth**: <br>\n",
    "* the maximum levels deep that each tree can grow (between 1 and infinity) \n",
    "* limits the number of nodes in the tree\n",
    "* if None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_sample_split samples\n",
    "\n",
    "**max_features**: \n",
    "* the number of features to consider when looking for the best split\n",
    "\n",
    "**min_samples_leaf**: <br>\n",
    "* another regularization hyperparameter that sets the minimum number of samples required to be at a lead node. <br>\n",
    "\n",
    "**verbose**: <br>\n",
    "* if 1 then it prints progress and performance once in a while (the more trees, the lower the frequency)\n",
    "* if greater than 1 then it prints progress and performance for every tree\n",
    "* default = 0\n",
    "\n",
    "**random_state**: <br>\n",
    "* sets a random seed for reproducibility\n",
    "\n",
    "**Source**: <br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df3a22-c74a-438a-8c18-ea4cc59b4994",
   "metadata": {},
   "source": [
    "The default of squared error is appropriate and will be used in the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f002c3-52b1-4412-a115-c8025c5cd932",
   "metadata": {},
   "source": [
    "## Train the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b60d035-1117-4658-b06f-15fe4d7997bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4670.6319            1.16m\n",
      "         2        3896.7238            1.07m\n",
      "         3        3265.6653            1.03m\n",
      "         4        2751.3441           59.90s\n",
      "         5        2332.3904           58.75s\n",
      "         6        1988.4962           57.95s\n",
      "         7        1709.5221           57.21s\n",
      "         8        1480.3053           56.41s\n",
      "         9        1288.6601           55.90s\n",
      "        10        1131.9695           55.11s\n",
      "        20         497.6781           48.60s\n",
      "        30         388.5262           42.31s\n",
      "        40         355.1915           36.22s\n",
      "        50         341.9470           30.13s\n",
      "        60         330.1980           24.08s\n",
      "        70         323.9775           18.02s\n",
      "        80         318.0555           12.01s\n",
      "        90         313.2941            6.04s\n",
      "       100         307.3791            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=22, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(random_state = 22, verbose = True)\n",
    "gbrt.fit(X_a_train, \n",
    "         y_a_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3cb9f-89f7-4085-b05f-d6e2d59f3f0d",
   "metadata": {},
   "source": [
    "## Make predictions on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe61054-1363-4083-bb7b-146b74438114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36201858, 22.70909011, -0.73730653, ..., 76.13522229,\n",
       "        0.94756016, 78.05174669])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction_a = gbrt.predict(X_a_test)\n",
    "y_prediction_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8f573-2dc5-4a2c-a8e2-3b961d88515d",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf095aea-7da1-4948-999f-1bd388c0d165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 307.23\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "\n",
    "mse_a = mean_squared_error(y_a_test, y_prediction_a)\n",
    "print(\"MSE: %0.2f\" % (mse_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6922c677-e45a-496b-be6e-fccdbb2f9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 17.53\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "\n",
    "rmse_a = np.sqrt (mse_a)\n",
    "print(\"RMSE: %0.2f\" % (rmse_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379fe88e-8ce7-4351-a8e8-b3b4402f1e55",
   "metadata": {},
   "source": [
    "## Plot training deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64795112-bb4a-43d6-b778-963c26c0c086",
   "metadata": {},
   "source": [
    "The training deviance in the context of an XGBoost regression model is a metric that measures the goodness of fit of the model on the training data. Specifically, the training deviance is the loss function of the XGBoost model on the training data at each stage of the boosting process.\n",
    "\n",
    "In the case of XGBoost regression, the loss function is usually the mean squared error (MSE) between the predicted values and the true target values. During the training process, the XGBoost model is iteratively fitted to the training data, with each iteration adding a new decision tree to the model. After each iteration, the training deviance is calculated as the MSE between the predicted values and the true target values on the training data.\n",
    "\n",
    "The training deviance is an important metric for monitoring the training process of an XGBoost regression model. It can be used to check for overfitting, as a model that is overfitting will have a decreasing training deviance but a increasing validation deviance. It can also be used to compare the performance of different models trained on the same dataset, with lower training deviance indicating a better fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1b77f-2c22-4b41-9f19-18b2acc661d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the test set deviance\n",
    "test_score = np.zeros((gbrt.n_estimators,), dtype=np.float64)\n",
    "for i, y_pred in enumerate(gbrt.staged_predict(X_a_test)):\n",
    "    test_score[i] = gbrt.loss_(y_a_test, y_pred)\n",
    "\n",
    "# Plot the deviance against boosting iterations\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(gbrt.n_estimators) + 1, gbrt.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(gbrt.n_estimators) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a4bc53-d0da-49a6-becb-192469f74fa8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4670.3949           54.82s\n",
      "         2        3897.8865           53.31s\n",
      "         3        3267.1672           52.14s\n",
      "         4        2751.4570           51.42s\n",
      "         5        2332.2837           50.79s\n",
      "         6        1991.2955           50.46s\n",
      "         7        1712.6558           50.09s\n",
      "         8        1483.9394           49.44s\n",
      "         9        1291.6169           48.96s\n",
      "        10        1134.9911           48.27s\n",
      "        20         501.3560           42.65s\n",
      "        30         390.2714           37.21s\n",
      "        40         358.7500           31.85s\n",
      "        50         341.0241           26.53s\n",
      "        60         332.1974           21.22s\n",
      "        70         326.4393           15.88s\n",
      "        80         320.7572           10.58s\n",
      "        90         314.1639            5.29s\n",
      "       100         308.8504            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4652.8286           55.09s\n",
      "         2        3881.8314           54.01s\n",
      "         3        3253.8460           53.15s\n",
      "         4        2740.5086           52.22s\n",
      "         5        2321.9399           51.69s\n",
      "         6        1982.1709           51.07s\n",
      "         7        1703.8582           50.64s\n",
      "         8        1472.0581           50.02s\n",
      "         9        1282.0137           49.52s\n",
      "        10        1127.9519           48.84s\n",
      "        20         496.8010           43.11s\n",
      "        30         387.5772           37.65s\n",
      "        40         354.4278           32.17s\n",
      "        50         340.1519           26.72s\n",
      "        60         330.0412           21.37s\n",
      "        70         324.0956           16.01s\n",
      "        80         318.5927           10.66s\n",
      "        90         312.5121            5.32s\n",
      "       100         308.0354            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4658.7499           54.98s\n",
      "         2        3886.1450           53.66s\n",
      "         3        3256.4525           52.86s\n",
      "         4        2743.4485           52.00s\n",
      "         5        2325.4020           51.39s\n",
      "         6        1982.5284           50.78s\n",
      "         7        1704.2321           51.02s\n",
      "         8        1476.0402           50.51s\n",
      "         9        1285.4661           50.55s\n",
      "        10        1129.1461           50.13s\n",
      "        20         495.3920           43.80s\n",
      "        30         386.6504           37.96s\n",
      "        40         356.2698           32.33s\n",
      "        50         339.1602           26.77s\n",
      "        60         329.1514           21.35s\n",
      "        70         321.4299           15.96s\n",
      "        80         316.8360           10.63s\n",
      "        90         310.5014            5.31s\n",
      "       100         305.6006            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4684.4941           56.21s\n",
      "         2        3908.6418           54.09s\n",
      "         3        3276.3223           52.71s\n",
      "         4        2759.0976           51.72s\n",
      "         5        2337.7518           51.05s\n",
      "         6        1996.1646           50.21s\n",
      "         7        1716.7233           49.74s\n",
      "         8        1483.7962           49.05s\n",
      "         9        1292.9966           48.59s\n",
      "        10        1137.4642           47.97s\n",
      "        20         499.1157           42.79s\n",
      "        30         389.0067           38.05s\n",
      "        40         355.7488           32.46s\n",
      "        50         341.8310           26.87s\n",
      "        60         332.9410           21.44s\n",
      "        70         326.3443           16.00s\n",
      "        80         318.7619           10.67s\n",
      "        90         313.0271            5.34s\n",
      "       100         306.9207            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4670.7355           55.20s\n",
      "         2        3897.2501           53.70s\n",
      "         3        3267.2868           52.26s\n",
      "         4        2751.8962           51.38s\n",
      "         5        2332.4041           50.64s\n",
      "         6        1991.4582           49.97s\n",
      "         7        1712.2613           49.54s\n",
      "         8        1479.3884           48.88s\n",
      "         9        1288.7685           48.43s\n",
      "        10        1133.6807           47.97s\n",
      "        20         498.8278           42.78s\n",
      "        30         388.6253           37.33s\n",
      "        40         356.6501           32.30s\n",
      "        50         340.4405           26.81s\n",
      "        60         331.1754           21.42s\n",
      "        70         319.9734           16.00s\n",
      "        80         313.8900           10.65s\n",
      "        90         310.3763            5.32s\n",
      "       100         305.8807            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4669.6264           55.04s\n",
      "         2        3895.7445           53.88s\n",
      "         3        3264.9874           52.81s\n",
      "         4        2752.3760           51.90s\n",
      "         5        2330.5648           51.27s\n",
      "         6        1989.0800           50.62s\n",
      "         7        1709.3581           50.27s\n",
      "         8        1477.1214           49.69s\n",
      "         9        1288.5596           49.31s\n",
      "        10        1132.9598           48.95s\n",
      "        20         498.1312           43.45s\n",
      "        30         386.6765           37.91s\n",
      "        40         354.8816           32.34s\n",
      "        50         337.9456           27.06s\n",
      "        60         328.9473           21.57s\n",
      "        70         323.6791           16.11s\n",
      "        80         316.4701           10.73s\n",
      "        90         310.5146            5.35s\n",
      "       100         306.8564            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4674.0261           56.27s\n",
      "         2        3899.4894           54.60s\n",
      "         3        3268.7769           52.92s\n",
      "         4        2753.5673           52.30s\n",
      "         5        2333.2887           51.60s\n",
      "         6        1992.1179           50.81s\n",
      "         7        1712.4621           50.19s\n",
      "         8        1479.6616           49.65s\n",
      "         9        1290.2578           49.08s\n",
      "        10        1134.4740           48.41s\n",
      "        20         498.6583           42.69s\n",
      "        30         389.5772           37.32s\n",
      "        40         356.3176           31.92s\n",
      "        50         337.4676           26.54s\n",
      "        60         326.7165           21.37s\n",
      "        70         320.0956           16.01s\n",
      "        80         313.7495           10.66s\n",
      "        90         310.1110            5.32s\n",
      "       100         306.5054            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4669.0401           54.33s\n",
      "         2        3894.8776           53.23s\n",
      "         3        3265.2457           52.21s\n",
      "         4        2750.4820           51.67s\n",
      "         5        2331.1511           50.83s\n",
      "         6        1990.6471           50.17s\n",
      "         7        1712.4186           49.66s\n",
      "         8        1479.1472           49.25s\n",
      "         9        1288.2818           48.74s\n",
      "        10        1132.5092           48.18s\n",
      "        20         496.7511           42.72s\n",
      "        30         387.4219           37.27s\n",
      "        40         356.0910           31.91s\n",
      "        50         339.6812           26.51s\n",
      "        60         329.5343           21.18s\n",
      "        70         322.7380           15.88s\n",
      "        80         317.9377           10.65s\n",
      "        90         311.9222            5.32s\n",
      "       100         307.1851            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4677.3490           55.33s\n",
      "         2        3902.4645           53.61s\n",
      "         3        3270.5444           52.47s\n",
      "         4        2754.6804           51.68s\n",
      "         5        2335.7837           51.06s\n",
      "         6        1990.9801           50.52s\n",
      "         7        1711.4617           50.09s\n",
      "         8        1482.3415           49.40s\n",
      "         9        1290.8420           48.93s\n",
      "        10        1133.8876           48.30s\n",
      "        20         497.7521           42.90s\n",
      "        30         388.1247           37.59s\n",
      "        40         354.9041           32.15s\n",
      "        50         337.7998           26.74s\n",
      "        60         327.8171           21.39s\n",
      "        70         321.2113           16.00s\n",
      "        80         315.2233           10.67s\n",
      "        90         312.0003            5.37s\n",
      "       100         305.1688            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4677.6191           54.39s\n",
      "         2        3902.6279           53.32s\n",
      "         3        3270.3857           52.64s\n",
      "         4        2755.6659           51.85s\n",
      "         5        2333.6704           51.12s\n",
      "         6        1992.2211           50.48s\n",
      "         7        1712.6191           50.20s\n",
      "         8        1483.1527           49.54s\n",
      "         9        1291.8740           49.07s\n",
      "        10        1136.3963           48.42s\n",
      "        20         498.6268           43.02s\n",
      "        30         386.2185           37.62s\n",
      "        40         352.2586           32.19s\n",
      "        50         337.4465           26.82s\n",
      "        60         326.6069           21.43s\n",
      "        70         320.2371           16.04s\n",
      "        80         314.7572           10.69s\n",
      "        90         307.9575            5.34s\n",
      "       100         302.4943            0.00s\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation \n",
    "# evaluate the model on several test sets (validation sets), so that we can make sure we don't get lucky on one single test set\n",
    "\n",
    "accuracies_a = cross_val_score(estimator = gbrt, X = X_a_train, y = y_a_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7642d826-b733-46ac-8625-fa78a43d5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.9466924  0.94432298 0.94365346 0.94482792 0.94667863 0.94379101\n",
      " 0.94468041 0.94403046 0.94361499 0.94446869]\n",
      "Mean of the metric: 0.9446760964515262\n",
      "Standard deviation of the metric: 0.0010788131046527134\n"
     ]
    }
   ],
   "source": [
    "# Mean and standard deviation of the accuracy metric\n",
    "\n",
    "print(\"Cross-validation scores:\", accuracies_a)\n",
    "print(\"Mean of the metric:\", accuracies_a.mean())\n",
    "print(\"Standard deviation of the metric:\", accuracies_a.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c42f9-3be6-4be6-991c-ef1aa3b5028e",
   "metadata": {},
   "source": [
    "The mean accuracy is 94.5%. <br>\n",
    "Similarly the standard deviation of the accuracies resulting from these 10 validation datasets is 0.1%. <br>\n",
    "\n",
    "Interpretation of the results: <br>\n",
    "Through k-Fold Cross Validation, we need to estimate the \"unbiased error\" on the dataset from this model. The mean is a good estimate of how the model will perform on the dataset. Then once we are convinced that the average error is acceptable, we train the same model on all of the dataset.\n",
    "<br>\n",
    "The Standard Deviation of the model’s accuracy simply shows that the variance of the model accuracy is 4.5%. This means the model can vary about 4.5%, which means that if we run our model on new data and get an accuracy of 96.6%, we know that this is like within 92.1 to 100% accuracy. Bias and accuracy sometimes don’t have an obvious relationship, but most of the time we can spot some bias in the validation or testing of our model when it does not preform properly on new data.\n",
    "\n",
    "Source: <br>\n",
    "* https://www.sqlservercentral.com/articles/model-selection-and-performance-boosting-with-k-fold-cross-validation-and-xgboost\n",
    "* https://www.kaggle.com/questions-and-answers/154600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfa469-2b91-4438-87f5-d088ea6ab8b6",
   "metadata": {},
   "source": [
    "## Improve accuracy through hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87482512-39b8-4e9c-89cb-716403f7da8d",
   "metadata": {},
   "source": [
    "**XGBoost Hyperparamter Optimization Methods**: <br>\n",
    "**exhaustive grid searches (GS)**: <br>\n",
    "* Exhaustive grid search (GS) is an exhaustive search over every combi of specified parameter values. It discovers the optimal settings by computing and comparing the cross-validation loss for each one. Ideally, for efficiency, the search pattern is random (Restrepo, 2018). <br>\n",
    "* Hyperparamter optimizer: model_selection.GridSearchCV(estimator, ...)\n",
    "\n",
    "**coordinate descent (CD)**: <br>\n",
    "* Coordinate descent (CD) may be the simplest optimization method for setting hyperparameters. Like gradient descent, it’s an iterative algorithm and searches one vector or direction of possible hyperparameter settings at a time and continues in the direction that appears to be most promising. It continues this scan until no further directions yield any more improvements (Restrepo, 2018). <br>\n",
    "\n",
    "**genetic algorithm **: <br>\n",
    "* Genetic algorithms are an entire class for optimization and work exceptionally well in discrete search spaces with many, or high, dimensions. They mimic natural selection by simulating a population of possible solutions and the most correct survive. New generations are generated either by crossbreeding, wherein two possible solutions are combined, or mutation, wherein individual parameter settings can “mutate” by being replaced. Fitness or “best” is defined as the options with the negative of the loss function (Restrepo, 2018). <br>\n",
    "\n",
    "**Source**: <br>\n",
    "https://towardsdatascience.com/mastering-xgboost-2eb6bce6bc76"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3ee51-1d1c-47be-81d3-b4417925eb5c",
   "metadata": {},
   "source": [
    "In the following section, grid search is used for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "930201cf-f488-47b5-bb9c-cf418470475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of hyperparameters to tune and corresponding ranges\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'subsample': [0.5, 0.75, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d2ff069-6671-45bd-9bca-6de2b6e3ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of 'GridSearchCV' and pass the model, the parameter grid, and the number of cross-validation folds\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbrt = GradientBoostingRegressor(random_state=22)\n",
    "\n",
    "grid_search = GridSearchCV(gbrt, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e31747-e65d-4bf8-aaff-35345ef386ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit grid search to the training data\n",
    "\n",
    "grid_search.fit(X_a_train, y_a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9a097-61d0-4a0e-9780-79b5fa98a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and the corresponding mean cross-validation score\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", np.sqrt(-grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6d107-117a-4ddd-8292-fc33129d8b3c",
   "metadata": {},
   "source": [
    "## Plot feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974e883-12fb-4a80-880c-7ea44c3051f8",
   "metadata": {},
   "source": [
    "Warning Careful, impurity-based feature importances can be misleading for high cardinality features (many unique values). As an alternative, the permutation importances of reg can be computed on a held out test set. See Permutation feature importance for more details.\n",
    "For this example, the impurity-based and permutation methods identify the same 2 strongly predictive features but not in the same order. The third most predictive feature, “bp”, is also the same for the 2 methods. The remaining features are less predictive and the error bars of the permutation plot show that they overlap with 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "local-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
